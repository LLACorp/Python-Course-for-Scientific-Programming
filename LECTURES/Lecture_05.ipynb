{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYTHON COURSE FOR SCIENTIFIC PROGRAMMING \n",
    "**Main Editor of this Lecture:**\n",
    "\n",
    "Xabier Oianguren Asua: oiangu9@gmail.com\n",
    "\n",
    "**The lecture is based on previous material prepared by:**\n",
    "\n",
    "Jan Scarabelli Calopa: Jan.Scarabelli@e-campus.uab.cat \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LECTURE V : File manipulation\n",
    "\n",
    "### $(1.)$ - [*FILE HANDLING*](#1)\n",
    "### $(2.)$ - [*MANIPULATE DIRECTORY STRUCTURES*](#2)\n",
    "### $(3.)$ - [*MANAGE NUMPY DATA*](#3)\n",
    "### $(4.)$ - [*ADDITIONAL FILE TYPES*](#4)\n",
    "\n",
    "### [FURTHER TOPICS NOT COVERED IN THE COURSE](#5)\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## $(1.)$ File Handing\n",
    "\n",
    "\n",
    "Despite each OS has its own system to create and access files, Python has its own file manipulation system that uses a common interface known as a \"file handle\".\n",
    "\n",
    "### (a) Open\n",
    "\n",
    "\n",
    "The key function for working with files in Python is the `open()` function. It takes two parameters: `filename`, and `mode`.\n",
    "\n",
    "There are four different methods (modes) for opening a file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Indicator (naive/extra) | Open a file to... | Opening mode + | Pointer Position |\n",
    "| --- | --- | --- | --- |\n",
    "| r/r+ | Read it. | +writing | Beginning |\n",
    "| w/w+ | Write on it. It **overwrites** the file if it already existed. Creates a new file otherwise | +reading | Beginning |\n",
    "| x/x+ | Write on it. `FileExistsError` raised and execution will stop if it already existed (safe mode). Creates a new file otherwise | +reading | Beginning | \n",
    "| a/a+ | Write at the end of an already existing file if it exists. Creates a new file otherwise. | +reading | End\n",
    "\n",
    "(In general, it is my advice to use the \"no +\" modes of operation, to avoid confusions.)\n",
    "\n",
    "Let's see an example. We want to open a file called `\"File.txt\"` in `\"w\"` mode. That is, we want to create a new file with that name or just overrite any file with such a name with the objective of writting data to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameHandle = open(\"File.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where:\n",
    "- `nameHandle` stands for the name we have invented to handle this file. That is, it will be our \"access\" to the file. If we want to write data to this file we will tell this object to do so.\n",
    "- `open()` is the function to open a file, as we have already said.\n",
    "- `\"File.txt\"` is the name (string) of the file we want to open.\n",
    "- `\"w\"` indicates we want to write on this file (in an overwritting way).\n",
    "\n",
    "##### Note on Encodings\n",
    "As a side note, remember that everything in the end (in the memeory of the computer) is saved and manipulated in bits (0-s and 1-s), this means that in reality in the memory of the computer there is nowhere a letter `a`. Instead if for example we want to encode the 27 characters of the alphabet, we could give each letter a unique tag using sequences of 5 bits (there are 32 possible sequences since $2^5=32$). If so, we could say `a` will be the sequence $00000$, `b` will be $00001$, `c` will be $00010$ etc. Such that in memory we will save the text `acb` as $000000001000001$. Then when we want to read it again, we will need to specify in which encoding the text is codified to be able to convert it back to characters.\n",
    "\n",
    "One of the first encoding standards for text was the so called ASCII standard based on the alphabet and symbols for English, which used 7 bits to encode about 127 different symbols or characters, among them the alphabetic characters, the numerical digits, symbols like `?` or `!` and some other special characters like `\\n` representing line breaks, or the EOF representing the end of a text file, among others.\n",
    "\n",
    "Today there are several standardized encodings, and each operative system (OS) has its preferred ones. ASCII was the main encoding used in Internet until December 2007, when it was surpassed by UTF-8 using 8 bits (and thus allowing double symbols to be coded).\n",
    "\n",
    "In the function `open()`, we can also add a thrid argument indicating the **encoding** for the characters we will deal with in this file. If we do not specify it, Python will just use the default encoding on the OS. But in general, we could specify any of the encodings listed in the following table of the official Python documentation:\n",
    "\n",
    "[https://docs.python.org/3/library/codecs.html#standard-encodings](https://docs.python.org/3/library/codecs.html#standard-encodings)\n",
    "\n",
    "for example we could write `'utf_8'` or `'ascii'` as a third argument, say:\n",
    "\n",
    "`open(\"File.txt\", \"w\", \"utf_8\") `\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Write and Close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file handle we have created (the variable we decided to call `fileHandle`) is in reality an object with a pointer to a specific position of the text file. You can imagine it as the **cursor** that appears when you are writting something on a computer, just that this time you cannont see where the cursor is (it is this what we called \"Pointer position\" in the first table of the lecture).\n",
    "\n",
    "Now, this file handle is like a variable, but which not only contains information, it also has associated functions that allow the user to do multiple things to the file pointed by the handle (it is a class instance, as we will comment in the end of the lecture). One of these functions is `.write()`. The string we pass to it as an argument will be written to the file in the last position we have added something (in the position of the cursor). That is, we can call to it multiple times and the added text will be sequential in the file.\n",
    "\n",
    "After manipulating the file, we **must** call to the `.close()` function! It is then when the text is really written to the file. Until then, there might be parts of the text we have sent using `.write()` that were left floating in a limbo (called a text **buffer**).\n",
    "\n",
    "Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileHandle = open(\"File.txt\",\"w\") #Creation of the file\n",
    "fileHandle.write(\"Hi!\\nWelcome to the python course.\\n\")\n",
    "fileHandle.write(\"Enjoy!\\n\")\n",
    "fileHandle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you now open the file \"File.txt\" that has been created in the directory where the Jupyter Notebook is, you will see that it contains the follwoing text:\n",
    "```\n",
    "Hi!\n",
    "Welcome to the python course.\n",
    "Enjoy\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed the strange character `\\n` we introcuced in the writting function as part of the string. The character `\\` is an escapement character, meaning that the following character must be treated in a speacial way. In this case, for example, the string `\\n` indicates the beginning of a new line. Another example is `\\t` which will be interpreted as a TAB space.\n",
    "\n",
    "Or for example, imagine we would like to write a double or single quote `\"` or `'` to the file. How could we do this? Since they are the string delimiters in Python we will find it to be impossible. Try it. For this, we have the special characters `\\\"` and `\\'` respectively!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, after having edited the file, we want to save the changes to let other programmes access its contents. To do so, we must use the `.close()` function.\n",
    "\n",
    "\n",
    "#### Notes on Relative and Absolute Paths\n",
    "As we said, the result of this operation will be the creation of the file in the same directory (**directory==folder**) as the Jupyter Notebook is saved. But, is it possible to create files in other locations? Absolutely! \n",
    "\n",
    "For that instead of just introducing the name of the file in `open()` as `\"File.txt\"` we will need to introduce the details of the **path** to the directory we want it to be saved. The path is the location of a file or directory in the tree of directories of the persistent memory of the computer. We can provide it in two ways. A **relative path** is a path given from the point the Python interpreter is being executed and on (in our case, from the directory of the Jupyter Notebook and down there). For instance, imagine you have the following tree of directories under the folder where this Jupyter Notebook called `Lecture_05.ipynb` is:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> /Python_Course/\n",
    "        |-> Lecture_05.ipynb   # we are here!\n",
    "        |-> /Folder_1/\n",
    "                |-> /Save_the_texts_here_Folder/\n",
    "                        |-> text1.txt\n",
    "                        |-> text2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, if we want to save the text in the folder \"Save_the_text_here_Folder\" under the folder \"Folder_1\" which is insider the \"Python_Course\" folder where this notebook is, you will do:\n",
    "\n",
    "`open(\"Folder_1/Save_the_texts_here_Folder/File.txt\", \"w\")`\n",
    "\n",
    "This path `\"Folder_1/Save_the_texts_here_Folder/File.txt\"` is a so called **relative path**.\n",
    "\n",
    "If instead you want to save things anywhere in the directory structure, we will need to write the full path from the beginning of the tree of folders, for example something like `\"/home/xabier/Documents/UAB/My_texts/File.txt\"`. This is called an **absolute path**, since there is no doubt where I am trying to save it. That is, even if I move the Jupyter Notebook to other places in memory, the text file will always be created in the same place! \n",
    "\n",
    "Ofcourse, this will work if those folders like `\"Folder_1\"` or `\"Documents\"` etc. already exist! Make sure they do. We will see in a moment how to create new directories using Python.\n",
    "\n",
    "##### Important note for Windows vs Linux/MacOS users\n",
    "In Linux and MacOS, the directory structure always starts in a `\"/\"` and the next subfolders are indicated with a bar `\"/\"`, like `\"/home/navau/Documents/UAB/My_texts/File.txt\"`. However, in Windows directory trees always start in the drive in which data is saved, typically `\"C:\\` and the separation between subdirectories is specified with an inverse bar `\"\\\"`. For example `\"C:\\Users\\navau\\Documents\\UAB\\My_texts\\File.txt\"`.\n",
    "\n",
    "##### Comment on File names\n",
    "If you really are into jumping from the naive user-side to a more advanced-computer user-side, you should **end** today **naming files** with **spaces** and strange characters! This is because many interpreters (not the case of Python, but you will save problems in the future) interpret the space as a finish mark and will stop reading the name of the file at that point. That is, avoid naming files as `\"¡My first text file is sugoi!.txt\"` and instead name it `\"My_first_text_file_is_sugoi.txt\"` or something of the like.\n",
    "\n",
    "##### Comment on Buffers\n",
    "In reality, when you tell the file handle `.write(\"this or that\")`, the text is not immediately saved in the text file in the memory of the computer. This is because these tasks are managed by the operative system, and if we keep interrupting its activity constantly by telling it to write little messages to memory the task could get very inefficient. Instead, the text is first accumulated in a temporary so called **buffer** by Python (in the RAM), until this text buffer is full and then the whole chunk of information to be saved is given as a whole to the operating system, who will now take care to write the text as soon as possible to disk. Note that in fact, the operating system will take that text and actually save it in yet another buffer, until it finds the moment to save stuff to disk. When you call `.close()` not only the file stops to be opened by python and lets other programs open it safely, but all the buffers are flushed and you can be sure the text is now really saved in disk. \n",
    "\n",
    "Of course, it could happen that if the computer suddenly shuts down while `close` has still not been called, the data written with `write` is lost forever (because it was still on an intermediate buffer). To avoid it and explicitly force python to send the buffer as it is to the operative system, you can use `filehandle.flush()`. In addition, you could actually force the operative system to write to disk using `os.fsync()`, a function from the `os` library, which you can import with `import os`. Yet, normally you need not force the operative system to do so, it is fast enough for general use-cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we had the function `.write()` we also have the instruction `.read()`, which if the file is opened in read mode `r`, allows us to read the content of a file (remember the encoding argument in case the read text looks non-sense). \n",
    "\n",
    "Calling `.read()` will output a string which will be the text of the file. We can save it to a variable for further processing, or just display it with `print()`.\n",
    "\n",
    "Let's see the following example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi!\n",
      "Welcome to the python course.\n",
      "Enjoy!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fileHandle = open(\"File.txt\",\"r\") #read only\n",
    "print(fileHandle.read())\n",
    "fileHandle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, even when reading it is convenient to use the `.close()` function when we are done, even if in this case, it is usually safe to have multiple readers reading the same file.\n",
    "\n",
    "Note that if the text file was very big (like tens of gigabytes, it is not the most typical thing however), reading the whole file at once could be problematic. Instead, the `.read()` function accepts an integer argument indicating the number of characters we want to read from the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi!\n",
      "W\n"
     ]
    }
   ],
   "source": [
    "fileHandle = open(\"File.txt\",\"r\") #read only\n",
    "print(fileHandle.read(5))\n",
    "fileHandle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `\\n` for the line jump is a character as well!\n",
    "\n",
    "Then, if we asked another 5 characters before closing the file, we would receive the following 5. This is because the **cursor** of this particular handle will have moved on 5 positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi!\n",
      "W\n",
      "well well\n",
      "elcom\n"
     ]
    }
   ],
   "source": [
    "fileHandle = open(\"File.txt\",\"r\") #read only\n",
    "print(fileHandle.read(5))\n",
    "print(\"well well\")\n",
    "print(fileHandle.read(5))\n",
    "fileHandle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget you could save the read string to a variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi!\n",
      "Welcom\n"
     ]
    }
   ],
   "source": [
    "fileHandle = open(\"File.txt\",\"r\") #read only\n",
    "text = fileHandle.read(5)\n",
    "\n",
    "text = text + fileHandle.read(5)\n",
    "print(text)\n",
    "fileHandle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can iterate over a file as well. A file will be interpreted as a list of strings where each element is a line of the file (where lines are defined as the different fragments separated by `\\n`-s).\n",
    "\n",
    "Consequently, we can use a `for()` loop to iterate over the lines of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi!\n",
      "\n",
      "Welcome to the python course.\n",
      "\n",
      "Enjoy!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fileHandle = open(\"File.txt\",\"r\")\n",
    "\n",
    "for line in fileHandle:\n",
    "    print(line)\n",
    "    \n",
    "fileHandle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the blank line between lines. This is because each of the `line`-s in each iteration is a string with the line of the text with a `\\n` at the end of the string, so when we print the line an extra new-line is printed, because the `print()` statement generates a new line by default (this is the reason why you needed extra consideration in the star printing exercise in lecture 2).\n",
    "\n",
    "As each `line` is a string, it is possible to avoid the `'\\n'` by not taking the last character of the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi!\n",
      "Welcome to the python course.\n",
      "Enjoy!\n"
     ]
    }
   ],
   "source": [
    "fileHandle = open(\"File.txt\",\"r\")\n",
    "for line in fileHandle:\n",
    "    print(line[:-1])\n",
    "fileHandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi!xDD\n",
      "Welcome to the python course.xDD\n",
      "Enjoy!xDD\n"
     ]
    }
   ],
   "source": [
    "fileHandle = open(\"File.txt\",\"r\")\n",
    "for line in fileHandle:\n",
    "    line = line[:-1] + 'xDD'\n",
    "    print(line)\n",
    "fileHandle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Readline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.readline()` function allows us to read just one line, without the need of iterations. Which line will be read will depend on the cursor's current position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi!\n",
      "W \n",
      " elcome to the python course.\n",
      " \n",
      " Enjoy!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fileHandle = open(\"File.txt\",\"r\")\n",
    "one = fileHandle.read(5)\n",
    "two = fileHandle.readline()\n",
    "three = fileHandle.readline()\n",
    "print(f\"{one} \\n {two} \\n {three}\")\n",
    "fileHandle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Readlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functions returns a list of strings containing all the lines of the file in order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi!\\n', 'Welcome to the python course.\\n', 'Enjoy!\\n']\n"
     ]
    }
   ],
   "source": [
    "fileHandle = open(\"File.txt\",\"r\")\n",
    "list_of_lines = fileHandle.readlines()\n",
    "fileHandle.close()\n",
    "\n",
    "print(list_of_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to print only a specific line in the file, let's say the second line, we could use the following instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the python course.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fileHandle = open(\"File.txt\",\"r\")\n",
    "second_line = fileHandle.readlines()[1]\n",
    "fileHandle.close()\n",
    "print(second_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time an existing file is opened with \"w\" mode, its content is **completely** overwritten and the `.write()` method will start writting from the beginning. To avoid it, we can use the append mode `\"a\"`. When we call `.write()` in this mode, the text will be written after the last line of the file, without overwritting anything.\n",
    "\n",
    "As an example, we are going to modify the file using `\"w\"`, an then we are going to add another line without deleting anything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result in writting mode:\n",
      "Everything has been erased!\n",
      "\n",
      "Result with append mode:\n",
      "Everything has been erased!\n",
      "Use 'a' parameter to avoid overwriting it!\n"
     ]
    }
   ],
   "source": [
    "print(\"Result in writting mode:\")\n",
    "#Overwrite file\n",
    "fileHandle = open(\"File.txt\",\"w\") \n",
    "fileHandle.write(\"Everything has been erased!\\n\")\n",
    "fileHandle.close()\n",
    "#Print result of \"w\"\n",
    "fileHandle = open(\"File.txt\",\"r\")\n",
    "print(fileHandle.read())\n",
    "fileHandle.close()\n",
    "\n",
    "print(\"Result with append mode:\")\n",
    "#Use of \"a\"\n",
    "fileHandle = open(\"File.txt\",\"a\")\n",
    "fileHandle.write(\"Use \\'a\\' parameter to avoid overwriting it!\")\n",
    "fileHandle.close()\n",
    "#Print result of \"a\"\n",
    "fileHandle = open(\"File.txt\",\"r\")\n",
    "print(fileHandle.read())\n",
    "fileHandle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the file did not exist `\"a\"` will create a new one, just like `\"w\"`.\n",
    "\n",
    "Now, what if we do not want any file to be overwritten nor appended new data. If we only want to create new files, but we want to be stopped if we try to write a file with the same name as an already existing one, we can use the `\"x\"` mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'File.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-718b1a5c3ebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Should return error if file already exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfileHandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfileHandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Let's try x mode\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfileHandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'File.txt'"
     ]
    }
   ],
   "source": [
    "#Should return error if file already exists\n",
    "fileHandle = open(\"File.txt\",\"x\") \n",
    "fileHandle.write(\"Let's try x mode\\n\")\n",
    "fileHandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileHandle = open(\"File2.txt\",\"x\")  # it will create a new file if it does not aleready exist\n",
    "fileHandle.write(\"Let's try x mode\\n\")\n",
    "fileHandle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Tell and Seek\n",
    "\n",
    "Now, imagine we would like to write or read not where the cursor currently is for a certain file handle, but in another place, or imagine we want to do something as a function of where the cursor is in the file. For this we have two methods.\n",
    "\n",
    "The method `.tell()` lets us know how many characters away from the beginning of the file the cursor of a file handle is currently.\n",
    "\n",
    "The method `.seek()` takes as argument an integer and moves the cursor to that character position (relative to the beginning of the file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of their usage here is a silly example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Every\n",
      "5\n",
      "28\n",
      "Use 'a' parameter to avoid overwriting it!\n"
     ]
    }
   ],
   "source": [
    "fileHandle = open(\"File.txt\",\"r\")\n",
    "print(fileHandle.tell())\n",
    "print(fileHandle.read(5)) # read first 5 characters\n",
    "print(fileHandle.tell())\n",
    "\n",
    "fileHandle.seek( fileHandle.tell()+len(fileHandle.readlines()[0])  ) # move cursor to the end of this first line\n",
    "print(fileHandle.tell())\n",
    "print(fileHandle.read()) # read remaining text from the position of the cursor\n",
    "fileHandle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) With\n",
    "\n",
    "Finally, it is worth noting a very convenient way to open a file, in which closing the file is automatically done and you will not need to worry about it. This is done with a `with` statement:\n",
    "```\n",
    "with open(\"File.txt\", \"r\") as fileHandle:\n",
    "    blah\n",
    "    blah\n",
    "```\n",
    "Under this statement, the `fileHandle` works as expected, but when the block of code finishes, the fileHandle is destroyed (and in this case the `.close()` method is automatically called).\n",
    "\n",
    "You can of course give the name you wish to the handle and you can use the mode you prefer `'r'`, `'a'` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything has been erased!\n",
      "Use 'a' parameter to avoid overwriting it!\n"
     ]
    }
   ],
   "source": [
    "with open(\"File.txt\", \"r\") as fileHandle:\n",
    "    print(fileHandle.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how if we try to call again the handle it will look like it has never existed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0cae39d53db3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "with open(\"File.txt\", \"r\") as handle:\n",
    "    print(handle.read(10))\n",
    "print(handle.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last Remark\n",
    "\n",
    "It goes without saying that you can open multiple handles that read the same file, or multiple handles to write to different files simultaneously (the case of multiple handles all of them writting to the same file, is a bit more tricky as you can imagine, and might not make much sense). You can similarly see what happens for the other opening modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything has been erased!\n",
      "Use 'a' parameter to avoid overwriting it!\n"
     ]
    }
   ],
   "source": [
    "handle1_read = open(\"File.txt\", \"r\")\n",
    "handle2_read = open(\"File.txt\", \"r\")\n",
    "handle1_write = open(\"New.txt\", \"w\")\n",
    "handle2_write = open(\"New2.txt\", \"w\")\n",
    "\n",
    "handle1_write.write( handle1_read.read() )\n",
    "print( handle2_read.read() )\n",
    "handle2_write.write( \"This is the last day!\" )\n",
    "\n",
    "handle1_read.close()\n",
    "handle2_read.close()\n",
    "handle1_write.close()\n",
    "handle2_write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or equivalently with some nested `with` statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading a Dictionary: the JSON format\n",
    "In general all the functions that read or write to files that you will find in Python libraries (e.g. the one we saw to import Excel files), use the `open()` function and file handlers.\n",
    "\n",
    "Another example is the `json`library. There is a standard format for data structures akin to Python dictionaries, called `JSON`, which is used in many data bases for example. Thus, many times data you download from a data-base will be in this format. It is useful to know how to import those files and how to export your dictionaries back to files you can share. You could create a function that reads it using `open()` and do all the parsing, but somebody has already doen that for you.\n",
    "\n",
    "We will need to first write `import json` (you import a set of functions related with it), then there are two functions you will use inside:\n",
    "\n",
    "#### `json.dump(<dictionary>, <file_handler_to_save>)` \n",
    "We place as first argument the dictionary and then the file handler of the new file to write. If you only place the name of the file (the standard way is to put it the `.json` extension), the file will be generated in the same place as where the notebook is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'People':[\"Arnau\", \"Gerard\", \"Artemis\", \"Jan\", \"Xabier\"], \\\n",
    "     'Surnames':['Parrilla', 'Navarro', 'Llabrés', \"Scarabelli\", \"Oianguren\" ],\n",
    "     'Favourite Number':[1, 2, 3, 4, 5],\n",
    "     'Counter':1000\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f=open(\"MyDictionary.json\", \"w\")\n",
    "json.dump(d, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `json.load(<file_handler_to_load>)`\n",
    "\n",
    "We place the file handler as the argument of the function and it will return a dictionary. As simple as that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'People': ['Arnau', 'Gerard', 'Artemis', 'Jan', 'Xabier'], 'Surnames': ['Parrilla', 'Navarro', 'Llabrés', 'Scarabelli', 'Oianguren'], 'Favourite Number': [1, 2, 3, 4, 5], 'Counter': 1000}\n"
     ]
    }
   ],
   "source": [
    "with open(\"MyDictionary.json\", \"r\") as handler: \n",
    "    D = json.load( handler )\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='2'></a>\n",
    "## $(2.)$ Manipulate Directory Structures\n",
    "\n",
    "Using Python not only we can program the reading, writting and formatting of text files, but we can also manipulate directories and general files. Create folders, destroy files etc.\n",
    "\n",
    "These things are generally done with the package `os` which we will need to import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The working directory (the implicit part of the relative paths)\n",
    "\n",
    "A first thing we might want to do in a program is knowing where in the directory structure this code is being run. For example, if we are runnign this Jupyter Notebook, we might want to have the absolute path of the Notebook. It is there where the python interpreter is working, meaning that by default (by using relative paths) the images, files and other outputs we generate or input files we want to look for, are going to be seeked in this **current working directory** (or **cwd**).\n",
    "\n",
    "We can get this path with the function `getcwd()` of the `os` library. That is, by calling `os.getcwd()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently code is being executed in /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES\n"
     ]
    }
   ],
   "source": [
    "my_current_path = os.getcwd()\n",
    "\n",
    "print(f\"Currently code is being executed in {my_current_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such that the files generated with the following two will be in the exact same location (overwritten):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"File.txt\", \"w\") as fileHandle:\n",
    "    fileHandle.write(\"Using a relative path\")\n",
    "    \n",
    "with open(my_current_path + \"/File.txt\", \"w\") as fileHandle:\n",
    "    fileHandle.write(\"Using an absolute path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could even change the working directory to a desired path with `os.chdir()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir( my_current_path ) # we will leave it where it is, but you could change it if you wish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating directories\n",
    "\n",
    "We can create a desired directory structure using `os.makedirs()`, it takes two main arguments. First we will specify the directory, or set of directories we wish to create as a string (a path, relative or absolute) and then a boolean argument called `exist_ok` specifying what to do in case the directory we are trying to create exists. If we say True, then if the directory already existed, it will be left as it was and the code will continue. If False, if the directory already existed, an error will be raised and the code execution will be stoped. **Note**: Nothing is overwritten in either case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs( \"A_new_top_directory/A_new_in_between_dir/A_bottom_directory\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that the directories have been created where the notebook is.\n",
    "Now, if you re-execute the same line, nothing will happen, but if you execute the next line an error will rise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'A_new_top_directory/A_new_in_between_dir/A_bottom_directory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5913f48b27c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"A_new_top_directory/A_new_in_between_dir/A_bottom_directory\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'A_new_top_directory/A_new_in_between_dir/A_bottom_directory'"
     ]
    }
   ],
   "source": [
    "os.makedirs( \"A_new_top_directory/A_new_in_between_dir/A_bottom_directory\", exist_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we could use absolute paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs( my_current_path+\"/A_new_top_directory/A_new_in_between_dir/A_bottom_directory\", exist_ok=True) \n",
    "# this was the same as the first example\n",
    "os.makedirs( \"/home/xabier/Documents/New_top_directory/Bottom_new_dir\", exist_ok=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But be careful, you might be creating directories in quite random places if you use absolute paths without a little thought!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing all the files and subdirectories in a directory\n",
    "\n",
    "You can have a list of the names of the files and folders within a given path using `os.listdir()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New.txt', 'A_new_top_directory', 'File.txt', 'Lecture_04.ipynb', 'Lecture_03.ipynb', 'File2.txt', 'data_example2.txt', 'Lecture_05.ipynb', 'Lecture_01.ipynb', 'Lecture_02.ipynb', '.ipynb_checkpoints', 'New2.txt']\n"
     ]
    }
   ],
   "source": [
    "list_of_files_in_working_dir = os.listdir( my_current_path )\n",
    "print(list_of_files_in_working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is the new directory we created previously!\n",
    "\n",
    "You can even get the tree of directories and files under a given path using `os.walk()` and passing it as its argument the path under which you want to walk over the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES\n",
      "New.txt\n",
      "File.txt\n",
      "Lecture_04.ipynb\n",
      "Lecture_03.ipynb\n",
      "File2.txt\n",
      "data_example2.txt\n",
      "Lecture_05.ipynb\n",
      "Lecture_01.ipynb\n",
      "Lecture_02.ipynb\n",
      "New2.txt\n",
      "\n",
      "\n",
      "Directories under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES\n",
      "A_new_top_directory\n",
      ".ipynb_checkpoints\n",
      "\n",
      "Files under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/A_new_top_directory\n",
      "\n",
      "\n",
      "Directories under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/A_new_top_directory\n",
      "A_new_in_between_dir\n",
      "\n",
      "Files under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/A_new_top_directory/A_new_in_between_dir\n",
      "\n",
      "\n",
      "Directories under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/A_new_top_directory/A_new_in_between_dir\n",
      "A_bottom_directory\n",
      "\n",
      "Files under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/A_new_top_directory/A_new_in_between_dir/A_bottom_directory\n",
      "\n",
      "\n",
      "Directories under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/A_new_top_directory/A_new_in_between_dir/A_bottom_directory\n",
      "\n",
      "Files under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/.ipynb_checkpoints\n",
      "Lecture_05-checkpoint.ipynb\n",
      "Lecture_04-checkpoint.ipynb\n",
      "\n",
      "\n",
      "Directories under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/.ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk( my_current_path ):\n",
    "    print(f\"\\nFiles under {root}\")\n",
    "    for name in files:\n",
    "        print(name)\n",
    "    print(f\"\\n\\nDirectories under {root}\")\n",
    "    for name in dirs:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it will recursively enter into the subdirectories and for each it will provide us with the files and directories within that root subdirectory.\n",
    "\n",
    "There is an additional argument in `os.walk()` which is a boolean called `topdown`. Its default value is True, and the walk is done top-down. If set to False, the walk will begin from the deepest layer and made bottom-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/A_new_top_directory/A_new_in_between_dir/A_bottom_directory\n",
      "\n",
      "\n",
      "Directories under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/A_new_top_directory/A_new_in_between_dir/A_bottom_directory\n",
      "\n",
      "Files under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/A_new_top_directory/A_new_in_between_dir\n",
      "\n",
      "\n",
      "Directories under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/A_new_top_directory/A_new_in_between_dir\n",
      "A_bottom_directory\n",
      "\n",
      "Files under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/A_new_top_directory\n",
      "\n",
      "\n",
      "Directories under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/A_new_top_directory\n",
      "A_new_in_between_dir\n",
      "\n",
      "Files under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/.ipynb_checkpoints\n",
      "Lecture_05-checkpoint.ipynb\n",
      "Lecture_04-checkpoint.ipynb\n",
      "\n",
      "\n",
      "Directories under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES/.ipynb_checkpoints\n",
      "\n",
      "Files under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES\n",
      "New.txt\n",
      "File.txt\n",
      "Lecture_04.ipynb\n",
      "Lecture_03.ipynb\n",
      "File2.txt\n",
      "data_example2.txt\n",
      "Lecture_05.ipynb\n",
      "Lecture_01.ipynb\n",
      "Lecture_02.ipynb\n",
      "New2.txt\n",
      "\n",
      "\n",
      "Directories under /home/melanie/Desktop/Python-Course-for-Scientific-Programming/LECTURES\n",
      "A_new_top_directory\n",
      ".ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk( my_current_path, topdown=False ):\n",
    "    print(f\"\\nFiles under {root}\")\n",
    "    for name in files:\n",
    "        print(name)\n",
    "    print(f\"\\n\\nDirectories under {root}\")\n",
    "    for name in dirs:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing files and directories\n",
    "\n",
    "A file can be removed using `os.remove()` and specifying the path of the file. We can also remove a directory using `os.rmdir()` and specifying as argument the path of the directory. Note that an error will be raised if you try to remove a directory that still contains files. To remove a driectory this way we first need to remove all its files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"File.txt\")\n",
    "os.rmdir(\"A_new_top_directory/A_new_in_between_dir/A_bottom_directory\")\n",
    "os.rmdir(\"A_new_top_directory/A_new_in_between_dir/\")\n",
    "os.rmdir(\"A_new_top_directory/\")\n",
    "\n",
    "# you can check how both have disappeared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know how to walk a subdirectory tree bottom-up (from the deepest layer to the specified directory in the `os.walk()` first argument), such that you get the absolute path to all its files and directories, and you know the functions to remove files and directories...are you thinking what I'm thinking? \n",
    "\n",
    "<del> Yeah, you could **erase all the files in your computer**, forever.<del>\n",
    "\n",
    "<img src=http://c.tenor.com/SIiE1YV8yloAAAAd/cat-boom.gif width=\"200\" height=\"200\"> \n",
    "\n",
    "Shhh, its a secret!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='3'></a>\n",
    "## $(3.)$ Manage Numpy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you have some numerical data in a `.txt` or `.csv` or any other text file, such that the numbers are separated in columns with some delimiter (commas, spaces or such) and rows with row separators `\\n` (that is, data that you could store in a matrix for example). You could import that data to a numpy array by using `open()` and accumulating numbers as strings until you arrive to the delimiters, point in which you stop reading, convert the string to a floating number and insert it to an array. We will do this in an exercise. To save an array in a file you could do the inverse.\n",
    "\n",
    "However, numpy (like any other data manipulation library) already provides us with some functions that do all of this and more for us.\n",
    "\n",
    "In particular, numpy can write to and load data to conventional text files like `.txt`, or to special numpy files where data can be saved more efficiently (read/write faster and/or compressed), files of extension `.npy` and `.npz`.\n",
    "\n",
    "### (a) Data from .txt files the \"handmade\" way: file.write() to write and file.read() to read\n",
    "\n",
    "Let's see how to do this with text files first. To do so, let's create using `open(,'w')` a new file in wich we will introduce some example values. Important: remember that the things we want to write with `open()` must be introduced in string format! Not as integer, floats, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_example.txt\",\"w\") as npHandle:\n",
    "    npHandle.write(\"1 2 3\\n4 5 6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we wanted to read it as an array with the knowledge we have so far, we could try to use the `open(,'r')` handle to read the file and in each line of the file try to accumulate the numbers until the number separator (in the above case a space), then convert it to a float and insert it to an empty array. Or just use the `.split()` method of the strings that allows splitting a string into a list given a splitting delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# build array of zeros\n",
    "a = np.zeros((2,3), dtype=int)\n",
    "\n",
    "# read the array using open()\n",
    "with open('data_example.txt', 'r') as datafile:\n",
    "    for k, row_string in enumerate(datafile):\n",
    "        a[k, :] = np.array(row_string.split(' '))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is a bit uncomfortable to do manually. Fortunatelly there are numpy functions to do both things for us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Data from .txt files using numpy: np.loadtxt() to read and np.savetxt() to save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.loadtxt()\n",
    "Lets now test the numpy function to directly read an array from the text file we generated previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.loadtxt(\"data_example.txt\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also possible with multidimensional arrays, where the '\\n' character will indicate by default the end of a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"data_np.txt\",\"w\") as npHandle:\n",
    "    npHandle.write(\"1 0 0\\n 0 1 0\\n 0 0 1\\n\")\n",
    "\n",
    "a = np.loadtxt(\"data_np.txt\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the `loadtxt()` function has some additional arguments. Among them, we can first impose a datatype for the read array (instead of the default numpy float), or we could choose a different delimiter. In the examples above we delimited each entry of the array in a same row with a space, but we could delimit it with any particular character, say with a comma `,`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"data_example2.txt\",\"w\") as npHandle:\n",
    "    npHandle.write(\"1,0,0\\n0,1,0\\n0,0,1\\n\")\n",
    "\n",
    "a = np.loadtxt(\"data_example2.txt\", dtype='int', delimiter=',')\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some optional arguments for loadtxt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some other interesting optional arguments like `skiprows` or `max_rows` for `loadtxt()`, which allow us to only read part of the array (skiping the first `skiprow` rows and reading only a maximum of `max_rows`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.savetxt(\"data_example4.txt\", np.identity(4))\n",
    "np.loadtxt(\"data_example4.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.loadtxt(\"data_example4.txt\", skiprows=1, max_rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also an argument to just read certain columns of the file named `usecols` which expects a list of the columns of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.loadtxt(\"data_example4.txt\", usecols=[0,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.savetxt()\n",
    "\n",
    "In the examples above we have been writing the arrays to disk using `open()`, which had the inconvenient that we needed to convert every number to a string, do it all manually etc. But numpy has a function to directly write an array to a text file `savetxt()`, which allows us to dump arrays to a file in a text format like `.txt` or `.csv`. The function takes as arguments, first the file name where to save things (as a relative or absolute path as always), then the array and then several optional arguments like the delimiter to use when writing the array to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n",
      "[1. 2. 3.]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1.0,2.0,3.0])\n",
    "\n",
    "np.savetxt(\"data_example3.txt\", a, delimiter=',') #default is ','\n",
    "\n",
    "b = np.loadtxt(\"data_example3.txt\")\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(np.array_equal( a,b )) # check that both arrays are equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Data from .npy or .npz files (using numpy of course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until here we used `.txt` files to save the arrays, just in text format. However, as you might imagine as text is not the most optimal way to save numbers!\n",
    "\n",
    "A `.npy` file is the standard **binary** (1 or 0) file to save numpy arrays. It is directly written as 1-s and 0-s, that is why if you open it, unlike the `.txt` or `.csv` files, you will not recognize anything. The point is that saving arrays to- and reading them from- `.npy` files is highly optimized and takes way less time than from standard text files. This difference gets tremendously noticeable for very big arrays, as we will check.\n",
    "\n",
    "A `.npz` file on the other hand is like a sort of \"zip\" of several numpy arrays. That is, it is a file where there are multiple arrays each in a `.npy` format, all in the same file. Numpy allows `.npz` files, or zips of numpy arrays, to be saved **compressed** or uncompressed.\n",
    "\n",
    "Let's see how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.save() and np.load()\n",
    "\n",
    "On the one hand, a **single** numpy array can be saved into a `.npy` file by simply using the `np.save()` function, and it can be loaded with `np.load()`. Both take as argument the path of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63 43 27  8 82 83]\n",
      " [49 29 77 61  3 37]\n",
      " [36 19 35 23 91 11]\n",
      " [48 76 94 13 76 75]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randint(low = 0, high = 100, size = (4,6))\n",
    "\n",
    "np.save(\"npyfile.npy\",a)\n",
    "\n",
    "b = np.load(\"npyfile.npy\")\n",
    "\n",
    "print(b)\n",
    "print(np.array_equal( a,b ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we do not need to take care for the data types (float, int etx.) with `.npy`, this information is also saved in the file.\n",
    "\n",
    "#### np.savez() and np.savez_compressed()\n",
    "On the other hand, if we wish to save several numpy arrays into a single file, we can use `savez()` or `savez_compressed()`. Both generate a kind of zip file with several `.npy` like entries for each saved array. The standard extension for this resulting file is `.npz`.\n",
    "\n",
    "The difference is that `savez()` will generate the file without compression (it will have the standard weight in memory) while `savez_compressed()` will compress the data when saving. Compressing means it will occupy less space in memory, but also that it will be slower to be saved and read (since the compression and decompression algorithms must be run). For all other purposes the behaviour of the file will be the same.\n",
    "\n",
    "Any `.npz` file will be readable using the `load()` function (just the same funciton that we used for `.npy` files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numpy.lib.npyio.NpzFile object at 0x7ff573388588>\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randint(low = 0, high = 100, size = (2,9))\n",
    "b = np.random.randint(low = 0, high = 100, size = (4,6))\n",
    "c = np.random.randint(low = 0, high = 100, size = (3,5))\n",
    "\n",
    "np.savez_compressed(\"npzfile.npz\", a, b, c)\n",
    "\n",
    "data_dict = np.load(\"npzfile.npz\")\n",
    "\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, after loading back the file, it does not print the three arrays as we could have expected. The reason for this is that `load()` returns a **dictionary of arrays** for the files `.npz`.\n",
    "\n",
    "In order to acces each of the arrays in the dictionary, you must access them using the key `'arr_i'` where 'i' stands for the i-th position of the array you wrote in `save_compressed()`. For instance we could recover the array we called `b` using `data_dict[arr_1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First array:\n",
      "\n",
      "[[56 66 25 95 50 47  0 78 22]\n",
      " [68 94 65  4 83 47 54 49 56]]\n",
      "\n",
      "Second array:\n",
      "\n",
      "[[14 60 93 78 91 20]\n",
      " [33 56 71 75 87 73]\n",
      " [ 9 53 10 97 21 69]\n",
      " [39 66  8 62  3 81]]\n",
      "\\Third array:\n",
      "\n",
      "[[23 81 15 86 30]\n",
      " [53 34 53 38 62]\n",
      " [73 30 90 36  8]]\n"
     ]
    }
   ],
   "source": [
    "print(\"First array:\\n\")\n",
    "print(data_dict[\"arr_0\"])\n",
    "\n",
    "print(\"\\nSecond array:\\n\")\n",
    "print(data_dict[\"arr_1\"])\n",
    "\n",
    "print(\"\\Third array:\\n\")\n",
    "print(data_dict[\"arr_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note there is a way to force the entries of the dictionary to have certain names for each array. Imagine instead of `'arr_0'` `'arr_1'` and `'arr_2'` we want to call them `'x'` `'y'` `'z'`, then we can achieve this generating the `.npz` file as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First array:\n",
      "\n",
      "[[56 66 25 95 50 47  0 78 22]\n",
      " [68 94 65  4 83 47 54 49 56]]\n",
      "\n",
      "Second array:\n",
      "\n",
      "[[14 60 93 78 91 20]\n",
      " [33 56 71 75 87 73]\n",
      " [ 9 53 10 97 21 69]\n",
      " [39 66  8 62  3 81]]\n",
      "\\Third array:\n",
      "\n",
      "[[14 60 93 78 91 20]\n",
      " [33 56 71 75 87 73]\n",
      " [ 9 53 10 97 21 69]\n",
      " [39 66  8 62  3 81]]\n"
     ]
    }
   ],
   "source": [
    "np.savez_compressed(\"npzfile.npz\", x=a, y=b, z=c)\n",
    "\n",
    "data_dict = np.load(\"npzfile.npz\")\n",
    "\n",
    "print(\"First array:\\n\")\n",
    "print(data_dict[\"x\"])\n",
    "\n",
    "print(\"\\nSecond array:\\n\")\n",
    "print(data_dict[\"y\"])\n",
    "\n",
    "print(\"\\Third array:\\n\")\n",
    "print(data_dict[\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or any other name you could give them (like a,b,c).\n",
    "\n",
    "### Proving that numpy formats .npy (and .npz) are faster to read and write than .txt\n",
    "\n",
    "Imagine you want to time a portion of your code. For this we have a function called `time()` in the `time` library, which returns CPU time in seconds. If you want to know the time taken by a certain block of code, you can then check the time before the block and after the block and see the difference.\n",
    "\n",
    "Lets use it to compare the saving and reading of arrays in `.txt` and `.npy`formats, using a naive `open()` method and using the numpy functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) using open() `.txt` - aka the \"handmade\" way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3000  # size for the array random datapoints\n",
    "a = np.random.randint(low=0, high=10000, size=(N,N))\n",
    "\n",
    "start_save = time()\n",
    "\n",
    "# save the array using open()\n",
    "with open('data.txt', 'w') as datafile:\n",
    "    for row in a:\n",
    "        for k,el in enumerate(row):\n",
    "            if k==len(row)-1:\n",
    "                datafile.write(str(el))\n",
    "            else:\n",
    "                datafile.write(str(el)+',')\n",
    "        datafile.write('\\n')\n",
    "\n",
    "end_save = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 9000000 points of data ###\n",
      "\n",
      "Data summary:\n",
      " [[1662 2830 4078 ... 1165 7677 8058]\n",
      " [6657 8667 3936 ... 5747 1471 2969]\n",
      " [6449 1962 3976 ... 2211 8071 9571]\n",
      " ...\n",
      " [5848 8134 7263 ... 4314 1717 7487]\n",
      " [2952 2262 9450 ... 4792 2790  240]\n",
      " [7488 2190 7580 ... 4253 1250 7314]]\n",
      "\n",
      "Saved and read arrays are equal True\n",
      "\n",
      "\n",
      "Data shape:\n",
      " (3000, 3000)\n",
      "\n",
      "Time to save using open: 7.51419 seconds.\n",
      "\n",
      "Time to read using open: 2.92075 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_read = time()\n",
    "\n",
    "# build array of zeros\n",
    "b = np.zeros((N,N), dtype=int)\n",
    "\n",
    "# read the array using open()\n",
    "with open('data.txt', 'r') as datafile:\n",
    "    for k, row_string in enumerate(datafile):\n",
    "        b[k] = np.array(row_string.split(','))\n",
    "\n",
    "end_read = time()\n",
    " \n",
    "total_save_time_open = end_save - start_save\n",
    "total_read_time_open = end_read - start_read\n",
    "\n",
    "print(f\"### {N**2} points of data ###\")\n",
    "print(\"\\nData summary:\\n\", b)\n",
    "print(f\"\\nSaved and read arrays are equal {np.array_equal(a,b)}\\n\")\n",
    "print(\"\\nData shape:\\n\", b.shape)\n",
    "print(f\"\\nTime to save using open: {round(total_save_time_open,5)} seconds.\")\n",
    "print(f\"\\nTime to read using open: {round(total_read_time_open,5)} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) using numpy savetxt() and loadtxt() `.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 9000000 points of data ###\n",
      "\n",
      "Data summary:\n",
      " [[1662. 2830. 4078. ... 1165. 7677. 8058.]\n",
      " [6657. 8667. 3936. ... 5747. 1471. 2969.]\n",
      " [6449. 1962. 3976. ... 2211. 8071. 9571.]\n",
      " ...\n",
      " [5848. 8134. 7263. ... 4314. 1717. 7487.]\n",
      " [2952. 2262. 9450. ... 4792. 2790.  240.]\n",
      " [7488. 2190. 7580. ... 4253. 1250. 7314.]]\n",
      "\n",
      "Saved and read arrays are equal True\n",
      "\n",
      "\n",
      "Data shape:\n",
      " (3000, 3000)\n",
      "\n",
      "Time to save using savetxt: 3.3579 seconds.\n",
      "\n",
      "Time to read using loadtxt: 3.99963 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_save = time()\n",
    "np.savetxt('data.txt', a)\n",
    "end_save = time()\n",
    "\n",
    "start_read = time()\n",
    "b = np.loadtxt('data.txt')\n",
    "end_read = time()\n",
    " \n",
    "total_save_time_savetxt = end_save - start_save\n",
    "total_read_time_loadtxt = end_read - start_read\n",
    "\n",
    "print(f\"### {N**2} points of data ###\")\n",
    "print(\"\\nData summary:\\n\", b)\n",
    "print(f\"\\nSaved and read arrays are equal {np.array_equal(a,b)}\\n\")\n",
    "print(\"\\nData shape:\\n\", b.shape)\n",
    "print(f\"\\nTime to save using savetxt: {round(total_save_time_savetxt,5)} seconds.\")\n",
    "print(f\"\\nTime to read using loadtxt: {round(total_read_time_loadtxt,5)} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) using numpy save() and load() `.npy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 9000000 points of data ###\n",
      "\n",
      "Data summary:\n",
      " [[1662 2830 4078 ... 1165 7677 8058]\n",
      " [6657 8667 3936 ... 5747 1471 2969]\n",
      " [6449 1962 3976 ... 2211 8071 9571]\n",
      " ...\n",
      " [5848 8134 7263 ... 4314 1717 7487]\n",
      " [2952 2262 9450 ... 4792 2790  240]\n",
      " [7488 2190 7580 ... 4253 1250 7314]]\n",
      "\n",
      "Saved and read arrays are equal True\n",
      "\n",
      "\n",
      "Data shape:\n",
      " (3000, 3000)\n",
      "\n",
      "Time to save using save: 0.04294 seconds.\n",
      "\n",
      "Time to read using load: 0.01662 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_save = time()\n",
    "np.save('data.npy', a)\n",
    "end_save = time()\n",
    "\n",
    "start_read = time()\n",
    "b = np.load('data.npy')\n",
    "end_read = time()\n",
    " \n",
    "total_save_time_save = end_save - start_save\n",
    "total_read_time_load = end_read - start_read\n",
    "\n",
    "print(f\"### {N**2} points of data ###\")\n",
    "print(\"\\nData summary:\\n\", b)\n",
    "print(f\"\\nSaved and read arrays are equal {np.array_equal(a,b)}\\n\")\n",
    "print(\"\\nData shape:\\n\", b.shape)\n",
    "print(f\"\\nTime to save using save: {round(total_save_time_save,5)} seconds.\")\n",
    "print(f\"\\nTime to read using load: {round(total_read_time_load,5)} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graphical comparison of the obtained times speaks by itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD4CAYAAADmWv3KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUvklEQVR4nO3dfZAc9X3n8ffXkihJIMCSNi5AkFXlQcESIEV7Aj2AY2xh/MSFOygg2BRgTuEIXEDKnZ3zVTCpuqqLCzgbmzNWDJF9FqSCImKDiziUY6KQlXB2kYgkFnKB8LCCg5XMg+RDCEnf+2NaYiWtdofV9uxO7/tVNbUzPd39+8709md7e379m8hMJEnV84HhLkCSVA4DXpIqyoCXpIoy4CWpogx4SaqoscNdQG9Tp07N1tbW4S5DkppGZ2fn1sxs6eu5ERXwra2tdHR0DHcZktQ0IuKFwz3nKRpJqigDXpIqyoCXpIoaUefgJake7777Lt3d3ezcuXO4S2mY8ePHM23aNMaNG1f3Mga8pKbT3d3NpEmTaG1tJSKGu5zSZSbbtm2ju7ub6dOn172cp2gkNZ2dO3cyZcqUURHuABHBlClT3vd/LAa8pKY0WsJ9n8G8XgNekirKgJfU9CJiSG8Duemmm/ja1762//EnPvEJrrnmmv2Ply1bxu23337AMnfddRff+973AFixYgUvv/zy0Lz4flQm4Id6A5d5k9TcFi5cSHt7OwB79+5l69atbN68ef/z7e3tLFiwYP/j3bt3c+2113LFFVcAjQt4e9FI0vu0YMECbrrpJgA2b97MrFmzeOWVV3j99deZOHEiXV1dLF26lHnz5vHYY49x2WWXsX37do455pj9Q7JcfvnlTJgwgbVr1/LUU0+xdOlSduzYwdSpU1mxYgUnnHDCEddZmSN4SWqUE088kbFjx/Liiy/S3t7O/PnzOfPMM1m7di0dHR2cdtppHHXUUezatYuOjg6WLVu2f9mLLrqItrY2Vq5cyYYNGxg7diw33HADq1atorOzk6uvvpovf/nLQ1KnR/CSNAgLFiygvb2d9vZ2li5dypYtW2hvb+e4445j4cKFrFu3jksuuWTA9TzzzDNs2rSJxYsXA7Bnz54hOXoHA16SBmXfefiNGzcya9YsTj75ZG677TaOPfZYrrrqKtatW8fRRx894Hoyk5kzZ7J27dohr9FTNJI0CAsWLOChhx5i8uTJjBkzhsmTJ/PGG2+wdu3aAz5g7cukSZPYvn07ADNmzKCnp2d/wL/77rsHfGB7JAx4SU0vM4f0Vo/TTjuNrVu3ctZZZx0w7bjjjmPq1Kn9LnvllVdy7bXXMnv2bPbs2cOqVav44he/yBlnnMHs2bP399A5UlHvi2mEtra2HOwXfjRT98OR9J5Lzairq4tTTz11uMtouL5ed0R0ZmZbX/N7BC9JFWXAS1JFGfCSVFGlBXxEzIiIDb1ub0XEjWW1J0k6UGn94DPzGWA2QESMAbYAD5TVniTpQI06RfMx4NnMfKFB7UnSqNeogL8UuK+vJyJiSUR0RERHT09Pg8qRVCURQ3urx5gxY5g9ezazZs3is5/9LG+88caQvJbW1la2bt06JOsqPeAj4ijgAuD+vp7PzOWZ2ZaZbS0tLWWXI0lDYsKECWzYsIFNmzYxefJk7rzzzuEu6RCNOIL/JPBEZr7agLYkqeHmz5/Pli1bAHj22Wc5//zzmTt3LmeffTZPP/00AA8++CBnnnkmc+bM4eMf/zivvlqLxG3btnHeeecxc+ZMrrnmmiG9ELIRAX8Zhzk9I0nNbs+ePfzkJz/hggsuAGDJkiV84xvfoLOzk1tvvZXrrrsOgEWLFrFu3TrWr1/PpZdeyle/+lUAbrnlFhYtWsTmzZu58MILefHFF4estlJHk4yIo4HFwO+W2Y4kNdrbb7/N7Nmz2bJlC6eeeiqLFy9mx44dtLe3c/HFF++f75133gGgu7ubSy65hFdeeYVdu3Yxffp0ANasWcPq1asB+PSnP80HP/jBIaux1CP4zPxFZk7JzDfLbEeSGm3fOfgXXniBzOTOO+9k7969HH/88WzYsGH/raurC4AbbriB66+/no0bN/Ltb3+bnTt3ll6jV7JK0hGYOHEid9xxB7fddhsTJ05k+vTp3H9/rU9JZvLkk08C8Oabb3LSSScB8N3vfnf/8ueccw733nsvAA8//DCvv/76kNVmwEtqeplDe3u/5syZw+mnn859993HypUrufvuuznjjDOYOXMmP/jBDwD4yle+wsUXX8zcuXMPGE745ptvZs2aNcycOZPVq1dzyimnDNXb4nDBw2EkvedSM3K44Pc4XLAkjUIGvCRVlAEvqSmNtlOdg3m9BrykpjN+/Hi2bds2akI+M9m2bRvjx49/X8uVeqGTJJVh2rRpdHd3M5oGKBw/fjzTpk17X8sY8JKazrhx4/ZfCarD8xSNJFWUAS9JFWXAS1JFGfCSVFEGvCRVlAEvSRVlwEtSRRnwklRRBrwkVVSpAR8Rx0fEqoh4OiK6ImJ+me1Jkt5T9lAFXwf+OjMvioijgIkltydJKpQW8BFxHHAOcCVAZu4CdpXVniTpQGWeopkO9AB/FhHrI+I7EXH0wTNFxJKI6IiIjtE0Mpwkla3MgB8L/CbwrcycA/wC+NLBM2Xm8sxsy8y2lpaWEsuRpNGlzIDvBroz8/Hi8SpqgS9JaoDSAj4z/y/wUkTMKCZ9DHiqrPYkSQcquxfNDcDKogfNc8BVJbcnSSqUGvCZuQFoK7MNSVLfvJJVkirKgJekijLgJamiDHhJqigDXpIqyoCXpIoy4CWpogx4SaooA16SKsqAl6SKMuAlqaIMeEmqKANekirKgJekijLgJamiDHhJqigDXpIqyoCXpIoy4CWpokr9TtaIeB7YDuwBdmem388qSQ1SasAXPpqZWxvQjiSpF0/RSFJFlR3wCfxNRHRGxJK+ZoiIJRHREREdPT09JZcjSaNH2QG/KDN/E/gk8HsRcc7BM2Tm8sxsy8y2lpaWksuRpNGj1IDPzC3Fz9eAB4B5ZbYnSXpPaQEfEUdHxKR994HzgE1ltSdJOlCZvWg+BDwQEfvauTcz/7rE9iRJvZQW8Jn5HHBGWeuXJPXPbpKSVFEGvCRVlAEvSRVlwEtSRRnwklRRA/aiiYjxwGeAs4ETgbep9Wf/UWZuLrc8SdJg9RvwEXELtXB/FHgceA0YD/w68D+K8F+Wmf9Ucp2SpPdpoCP4n2XmzYd57vaI+CXglCGuSZI0BPoN+Mz80cHTIuIDwDGZ+VYxxsxrZRUnSRq8uj5kjYh7I+LYYkyZTcBTEfGfyy1NknQk6u1F8+HMfAv4beBhYDrw+bKKkiQduXoDflxEjKMW8D/MzHepfZmHJGmEqjfgvw08DxwNrImIXwbeKqsoSdKRqyvgM/OOzDwpMz+VmQm8CHy03NIkSUei34CPiM8VvWYOkDW7I+JXImJReeVJkgZroH7wU4D1EdEJdAI91C50+lXgI8BW4EulVihJGpSB+sF/PSK+CZwLLAROpzZUQRfw+cx8sfwSJUmDMeBYNJm5B3ikuEmSmkTpo0lGxJiIWB8RD5XdliTpPY0YLvj3qZ3SkSQ1UKkBHxHTgE8D3ymzHUnSoeodi+ZDEXF3RDxcPP5wRHyhjkW/BvwXYO/gS5QkDUa9R/ArgB9T+8IPgH8GbuxvgYj4DPBaZnYOMN+SiOiIiI6enp46y5GGT0Rz3KR6A35qZv4FxZF4Zu4G9gywzELggoh4Hvhz4NyI+P7BM2Xm8sxsy8y2lpaW+iuXJPWr3oD/RURMoRhgLCLOAt7sb4HM/MPMnJaZrcClwN9m5ueOpFhJUv0G7AdfWAr8EPiViPgHoAW4qLSqJElHrK6Az8wnIuIjwAwggGeKIYPrkpmPUvteV0lSg9QV8BExBvgU0Fosc15EkJm3l1ibJOkI1HuK5kFgJ7ARuzxKUlOoN+CnZebppVYiSRpS9faieTgiziu1EknSkKr3CH4d8EDx5R/vUvugNTPz2NIqkyQdkXoD/nZgPrCx+Mo+SdIIV+8pmpeATYa7JDWPeo/gnwMeLQYbe2ffRLtJStLIVW/A/2txO6q4SZJGuHqvZL2l7EIkSUOr34CPiG9m5vUR8SDFQGO9ZeYFpVUmSToiAx3BXwFcD9zagFokSUNooIB/FiAz/64BtWiUiCb5Ngo7janZDRTwLRGx9HBP2otGkkaugQJ+DHAMtStXJUlNZKCAfyUz/7ghlUiShtRAV7J65C5JTWqggP9YQ6qQJA25fgM+M3/eqEIkSUOr3sHG3reIGB8RP4uIJyNic0R4NawkNVC9Y9EMxjvAuZm5IyLGAY9FxMOZua7ENiVJhdICvhhaeEfxcFxx88oRSWqQ0k7RAETEmIjYALwGPJKZj/cxz5KI6IiIjp6enjLLkaRRpdSAz8w9mTkbmAbMi4hZfcyzPDPbMrOtpaWlzHIkaVQp8xz8fpn5RkT8FDgf2NSINptNkwzPAoBDtEjNocxeNC0RcXxxfwKwGHi6rPYkSQcq8wj+BOC7ETGG2h+Sv8jMh0psT5LUS5m9aP4JmFPW+iVJ/Sv1Q1ZJ0vAx4CWpogx4SaooA16SKsqAl6SKMuAlqaIMeEmqKANekirKgJekijLgJamiDHhJqigDXpIqyoCXpIoy4CWpogx4SaooA16SKsqAl6SKMuAlqaIMeEmqqNICPiJOjoifRsRTEbE5In6/rLYkSYcq7Uu3gd3Assx8IiImAZ0R8UhmPlVim5KkQmlH8Jn5SmY+UdzfDnQBJ5XVniTpQA05Bx8RrcAc4PE+nlsSER0R0dHT09OIciRpVCg94CPiGOAvgRsz862Dn8/M5ZnZlpltLS0tZZcjSaNGqQEfEeOohfvKzFxdZluSpAOV2YsmgLuBrsy8vax2JEl9K/MIfiHweeDciNhQ3D5VYnuSpF5K6yaZmY8BUdb6JUn980pWSaooA16SKsqAl6SKMuAlqaIMeEmqKANekirKgJekijLgJamiDHhJqigDXpIqyoCXpIoy4CWpogx4SaooA16SKsqAl6SKMuAlqaIMeEmqKANekiqqzC/dviciXouITWW1IUk6vDKP4FcA55e4fklSP0oL+MxcA/y8rPVLkvo37OfgI2JJRHREREdPT89wlyNJlTHsAZ+ZyzOzLTPbWlpahrscSaqMYQ94SVI5DHhJqqgyu0neB6wFZkREd0R8oay2JEmHGlvWijPzsrLWLUkamKdoJKmiDHhJqigDXpIqyoCXpIoy4CWpogx4SaooA16SKsqAl6SKMuAlqaIMeEmqKANekirKgJekijLgJamiDHhJqigDXpIqyoCXpIoy4CWpogx4SaooA16SKqrUgI+I8yPimYj4l4j4UpltSZIOVFrAR8QY4E7gk8CHgcsi4sNltSdJOtDYEtc9D/iXzHwOICL+HPi3wFMltilpiETEcJdQt8w8ZFoTlU8f5Q+JMgP+JOClXo+7gTMPnikilgBLioc7IuKZEmsaESJiKrB1uOsYrGbacY6E26l5jPJt9cuHe6LMgK9LZi4Hlg93HY0UER2Z2Tbcdah/bqfm4bbqW5kfsm4BTu71eFoxTZLUAGUG/D8CvxYR0yPiKOBS4IcltidJ6qW0UzSZuTsirgd+DIwB7snMzWW112RG1SmpJuZ2ah5uqz5EX58+S5Kan1eySlJFGfCSVFEG/AgVEXMi4u7i/mci4o+HuyYNLCJ+KyIW1DHflRFxYiNq0uhlwI9c/xW4o7j/I+CzETFxGOtRfX4LGDDggSsBA16lMuAHKSKWRsSm4nZjRLRGxNMRsTIiuiJi1b5Ajoi5EfF3EdEZET+OiBOK6Y9GxJ9ExM8i4p8j4uxi+iTg9Mx8EiBrn4Q/CnxmeF7tyFO8310R8acRsTki/iYiJhTPPRoRbcX9qRHxfHH/yoj4q4h4JCKej4jri+24PiLWRcTkXst/PSI2FNt3XkR8ICL+T0S0FPN8oBhEr6V3TcC1wE3FsmdHxA8i4ori+d8tfj8uAtqAlcV8Exr3zjXGSNw+xfSvRMQ9xTqei4j/1KveQ/bfiDg3Iv6q1/KLI+KBRryHQ8GAH4SImAtcRW3ohbOA/wB8EJgB/K/MPBV4C7guIsYB3wAuysy5wD3Af++1urGZOQ+4Ebi5mNYGbDqo2Q7g7FJeUPP6NeDOzJwJvAH8+zqWmQX8O+DfUNsO/y8z5wBrgSt6zTcxM2cD11Hr4rsX+D5wefH8x4EnM7Nn3wKZ+TxwF/A/M3N2Zv49tWE4/qj4470MuCEzV1HbnpcX8709mBffBEbU9unlN4BPUBsv6+ZiH4U+9l/gp8Bv9PpDcRW1fbgpGPCDswh4IDN/kZk7gNXUwvelzPyHYp7vF/PNoPZL+0hEbAD+G7WrevdZXfzsBFqL+ycAB/9ivob/0h/sXzNzQ3G/9/vXn59m5vZix38TeLCYvvGg5e8DyMw1wLERcTy1HXtfyFwN/NlAjWXmq8AfUQuKZZn58zpqrIqRun1+lJnvZOZWavvVh4rph+y/xX/P/xv4XNHGfODhOl7HiDDsY9FUzMEXFSQQwObMnH+YZd4pfu7hve3xNjD+oPnGF9P1nnd63d8D7DvVsZv3Dl4Ofh97L7O31+O9HLg/HLItM/OliHg1Is6ldvR3OfU5DdjG6PsDPVK3z8F17VtvX/sv1P5QPAjsBO7PzN2HWe+I4xH84Pw98NvFObqjgQuLaadExL4g/x3gMeAZoGXf9IgYFxEzB1h/F/CrB037dQ49baO+PQ/MLe5fNMh1XAIQEYuANzPzzWL6d6gd3d2fmXv6WG47MGnfg4iYR+07EeYAfxAR0/uab5R5nuHbPv3pa/8lM18GXqb23/eA/7WNJAb8IGTmE8AK4GfA49R+qV6nFua/FxFd1M7Jfyszd1H7Jf6TiHgS2MAAvSwy82nguOLD1n0+Sq03jQZ2K/AfI2I9MHWQ69hZLH8X8IVe038IHMPhd/QHgQuLDwA/AvwpcHUREsuAeyIiqP3+3FXVD1kHMJzbpz+H7L+9nltJ7RRO1yDrHRYOVTBEih4UD2XmrCFa303A9sz8TkR8CLg3Mz82FOtW/yLiUeAPMrOjj+faqH2I6gfew6SM7TPQ/hsR3wTWZ+bd77/i4eMR/Mj1Ld47V3gKtaM/DaOofa/wXwJ/ONy16FBlbZ+I6AROp3bqp6l4BC9JFeURvCRVlAEvSRVlwEtSRRnwklRRBrwkVdT/B5rQjsRcro/iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "X = np.arange(3)\n",
    "ax.bar(X + 0.00, [total_save_time_open, total_save_time_savetxt, total_save_time_save], color = 'k', width = 0.4, label=\"Write\")\n",
    "ax.bar(X + 0.45, [total_read_time_open, total_read_time_loadtxt, total_read_time_load], color = 'b', width = 0.4, label=\"Read\")\n",
    "ax.set_xticks(X+0.2, ('open()', 'numpy txt', 'numpy npy'))\n",
    "ax.set_ylabel(\"Time (s)\")\n",
    "#ax.set_xlabel(\"Method\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='4'></a>\n",
    "\n",
    "## $(4.)$ Additional File types\n",
    "\n",
    "Since Python is open source, there are plenty of libraries for almost anything you can imagine. This means that you can find libraries for not only manipulating raw text files like we have, but also to automatically generate `excel` files with the data you have processed, `csv` files etc.\n",
    "\n",
    "Not only that, but you can dump any kind of Python variable or object to a permanent file. Check the `pickle` or `dill`libraries for this. For dictionaries in particular, you can also use the `json` library (which is a standard file extension as well). We will learn how to use the `json` library to input and output data in the exercises.\n",
    "\n",
    "Also, we have not talked about it, but there are ways to not only dump the raw data to a file, but to dump it in a compressed manner! Such that the generated files occupy much less space. For numpy arrays for example, we have the `h5py` library that allows generating massive `.h5` dataset files in a compressed manner, with easy access to different numpy arrays just using a tag for them and without the need to import the whole dataset to RAM in order to use its parts! Yeah, miracles exist.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we finish, remove all the stuff we have created! Specially the last arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"data.txt\")\n",
    "os.remove(\"data.npy\")\n",
    "os.remove(\"data_example.txt\")\n",
    "os.remove(\"data_example2.txt\")\n",
    "os.remove(\"data_example3.txt\")\n",
    "os.remove(\"data_example4.txt\")\n",
    "os.remove(\"data_np.txt\")\n",
    "os.remove(\"File2.txt\")\n",
    "os.remove(\"New.txt\")\n",
    "os.remove(\"New2.txt\")\n",
    "os.remove(\"npyfile.npy\")\n",
    "os.remove(\"npzfile.npz\")\n",
    "os.remove(\"MyDictionary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------\n",
    "---\n",
    "<a id='5'></a>\n",
    "\n",
    "# Further Topics Not Covered in the Course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color in, color out...the course has arrived to its end!\n",
    "\n",
    "But don't be sad! There are way more things to know about python that we didn't have time to cover here!\n",
    "\n",
    "Here you have a list of the possible following topics you could attack to deepen your programming skills:\n",
    "\n",
    "\n",
    "- Using `.py` scripts to code instead of a Jupyter Notebook, running scripts from a terminal/console.\n",
    "\n",
    "\n",
    "- Data manipulation libraries like `pandas`.\n",
    "\n",
    "\n",
    "- Object Oriented Programming: the `class` conondrum.\n",
    "\n",
    "\n",
    "- `map` and `lambda` functions.\n",
    "\n",
    "\n",
    "- Manipulating images, videos, sound and other more exotic data types (libraries like `openCV, sounddevice` ...)\n",
    "\n",
    "\n",
    "- Machine Learning and Deep Learning (libraries like `pytorch, scikit-learn, tensorflow` ...)\n",
    "\n",
    "\n",
    "- Parallel processing using several CPU cores or using the GPU itself (`mpi4py, multiprocessing, pytorch` ...)\n",
    "\n",
    "\n",
    "- Calling C/C++ functions under the hood (`ctypes` ...)\n",
    "\n",
    "\n",
    "- Graphical user interfaces (`pyQt` ...)\n",
    "\n",
    "\n",
    "- Standalone executables (`pyinstaller` ...)\n",
    "\n",
    "\n",
    "- Web/mobile application development (`flask` ...)\n",
    "\n",
    "\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the basic notions for Python programming, you could follow almost any online course to continue exploring everything Python has to offer! You can look for free courses in pages like EdX, Coursera or even Youtube itself!\n",
    "\n",
    "What is more, once you have integrated the concepts you have learnt here, you could even try to give a chance to other lower level programming languages as well! They are more complicated to program (you must have into account more things), but the essentials are the same.\n",
    "\n",
    "And if not, note that unless you need some very very fast and optimized code you can manage with python. In fact, remember that most of the important libraries (numpy, pytorch, mpi4py etc.) in reality execute C or Fortran code under the hood, so the speed up is already available with Python, without requiring you to go down to the kitchen of hell!\n",
    "\n",
    "\n",
    "It has been a pleasure to have you here!\n",
    "\n",
    "For anything you need, you have our emails at the beginning of the notebooks,\n",
    "\n",
    "\n",
    "**LLA & SCN$^\\textbf{2}$** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
